{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ae5df91",
   "metadata": {},
   "source": [
    "##### Marketing for Financial Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8e02b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1fb911c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abe64fd6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Customer_and_bank_details_p1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Import Datasets\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m bd \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCustomer_and_bank_details_p1.csv\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m#Bank details\u001b[39;00m\n\u001b[0;32m      3\u001b[0m cd \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCustomer_campaign_details_p1.csv\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m#Campaign Details\u001b[39;00m\n\u001b[0;32m      4\u001b[0m sed \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCustomer_social_economic_data_p1.csv\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m#SocialEconomic Details\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1736\u001b[0m     f,\n\u001b[0;32m   1737\u001b[0m     mode,\n\u001b[0;32m   1738\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1739\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1740\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1741\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1742\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1743\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1744\u001b[0m )\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    859\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    860\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    861\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Customer_and_bank_details_p1.csv'"
     ]
    }
   ],
   "source": [
    "# Import Datasets\n",
    "bd = pd.read_csv('Customer_and_bank_details_p1.csv') #Bank details\n",
    "cd = pd.read_csv('Customer_campaign_details_p1.csv') #Campaign Details\n",
    "sed = pd.read_csv('Customer_social_economic_data_p1.csv') #SocialEconomic Details\n",
    "res = pd.read_csv('Customer_Response_data_p1.csv') #Campign Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b41a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "st = pd.read_csv('State_Master.csv') #State codes\n",
    "rg = pd.read_csv('Region_code_master.csv') #Region codes\n",
    "city = pd.read_csv('City_Master.csv')#City codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e5321d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(st.shape)\n",
    "print(rg.shape)\n",
    "print(city.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78c0984",
   "metadata": {},
   "source": [
    "###### Getting to know the datatypes of columns and other info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4bcf4608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37084, 11)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37084 entries, 0 to 37083\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Customer_id  37084 non-null  int64 \n",
      " 1   age          37084 non-null  int64 \n",
      " 2   job          37084 non-null  object\n",
      " 3   marital      37084 non-null  object\n",
      " 4   education    37084 non-null  object\n",
      " 5   default      37084 non-null  object\n",
      " 6   housing      37084 non-null  object\n",
      " 7   loan         37084 non-null  object\n",
      " 8   Region_Code  37084 non-null  object\n",
      " 9   State_Code   37084 non-null  object\n",
      " 10  City_Code    37084 non-null  object\n",
      "dtypes: int64(2), object(9)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "print(bd.shape)\n",
    "bd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "182e941e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37084, 9)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37084 entries, 0 to 37083\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Customer_id  37084 non-null  int64 \n",
      " 1   contact      37084 non-null  object\n",
      " 2   month        37084 non-null  object\n",
      " 3   day_of_week  37084 non-null  object\n",
      " 4   duration     37084 non-null  int64 \n",
      " 5   campaign     37084 non-null  int64 \n",
      " 6   pdays        37084 non-null  int64 \n",
      " 7   previous     37084 non-null  int64 \n",
      " 8   poutcome     37084 non-null  object\n",
      "dtypes: int64(5), object(4)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "print(cd.shape)\n",
    "cd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33213910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37084, 6)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37084 entries, 0 to 37083\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Customer_id     37084 non-null  int64  \n",
      " 1   emp.var.rate    37084 non-null  float64\n",
      " 2   cons.price.idx  37084 non-null  float64\n",
      " 3   cons.conf.idx   37084 non-null  float64\n",
      " 4   euribor3m       37084 non-null  float64\n",
      " 5   nr.employed     37084 non-null  float64\n",
      "dtypes: float64(5), int64(1)\n",
      "memory usage: 1.7 MB\n"
     ]
    }
   ],
   "source": [
    "print(sed.shape)\n",
    "sed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c423a53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37084, 2)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37084 entries, 0 to 37083\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Customer_id  37084 non-null  int64 \n",
      " 1   y            37084 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 579.6+ KB\n"
     ]
    }
   ],
   "source": [
    "print(res.shape)\n",
    "res.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacd7cb9",
   "metadata": {},
   "source": [
    "##### The number of rows in all the tables is same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a9ce522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37084 entries, 0 to 37083\n",
      "Data columns (total 28 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Customer_id     37084 non-null  int64  \n",
      " 1   age             37084 non-null  int64  \n",
      " 2   job             37084 non-null  object \n",
      " 3   marital         37084 non-null  object \n",
      " 4   education       37084 non-null  object \n",
      " 5   default         37084 non-null  object \n",
      " 6   housing         37084 non-null  object \n",
      " 7   loan            37084 non-null  object \n",
      " 8   Region_Code     37084 non-null  object \n",
      " 9   State_Code      37084 non-null  object \n",
      " 10  City_Code       37084 non-null  object \n",
      " 11  Customer_id     37084 non-null  int64  \n",
      " 12  emp.var.rate    37084 non-null  float64\n",
      " 13  cons.price.idx  37084 non-null  float64\n",
      " 14  cons.conf.idx   37084 non-null  float64\n",
      " 15  euribor3m       37084 non-null  float64\n",
      " 16  nr.employed     37084 non-null  float64\n",
      " 17  Customer_id     37084 non-null  int64  \n",
      " 18  contact         37084 non-null  object \n",
      " 19  month           37084 non-null  object \n",
      " 20  day_of_week     37084 non-null  object \n",
      " 21  duration        37084 non-null  int64  \n",
      " 22  campaign        37084 non-null  int64  \n",
      " 23  pdays           37084 non-null  int64  \n",
      " 24  previous        37084 non-null  int64  \n",
      " 25  poutcome        37084 non-null  object \n",
      " 26  Customer_id     37084 non-null  int64  \n",
      " 27  y               37084 non-null  object \n",
      "dtypes: float64(5), int64(9), object(14)\n",
      "memory usage: 7.9+ MB\n"
     ]
    }
   ],
   "source": [
    "#Concatinate the dataset\n",
    "df = pd.concat([bd, sed, cd,res], axis=1, join=\"inner\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be8ce8d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_id</th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>State_Code</th>\n",
       "      <th>City_Code</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>S1</td>\n",
       "      <td>C1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>307</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>S1</td>\n",
       "      <td>C1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>S2</td>\n",
       "      <td>C2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>139</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>S3</td>\n",
       "      <td>C3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>217</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>S3</td>\n",
       "      <td>C3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>380</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Customer_id  age          job  marital            education  default  \\\n",
       "0            1   56     services  married          high.school       no   \n",
       "1            2   45     services  married             basic.9y  unknown   \n",
       "2            3   59       admin.  married  professional.course       no   \n",
       "3            4   41  blue-collar  married              unknown  unknown   \n",
       "4            5   24   technician   single  professional.course       no   \n",
       "\n",
       "  housing loan Region_Code State_Code City_Code  emp.var.rate  cons.price.idx  \\\n",
       "0      no  yes           3         S1        C1           1.1          93.994   \n",
       "1      no   no           3         S1        C1           1.1          93.994   \n",
       "2      no   no           4         S2        C2           1.1          93.994   \n",
       "3      no   no           3         S3        C3           1.1          93.994   \n",
       "4     yes   no           3         S3        C3           1.1          93.994   \n",
       "\n",
       "   cons.conf.idx  euribor3m  nr.employed    contact month day_of_week  \\\n",
       "0          -36.4      4.857       5191.0  telephone   may         mon   \n",
       "1          -36.4      4.857       5191.0  telephone   may         mon   \n",
       "2          -36.4      4.857       5191.0  telephone   may         mon   \n",
       "3          -36.4      4.857       5191.0  telephone   may         mon   \n",
       "4          -36.4      4.857       5191.0  telephone   may         mon   \n",
       "\n",
       "   duration  campaign  pdays  previous     poutcome   y  \n",
       "0       307         1    999         0  nonexistent  no  \n",
       "1       198         1    999         0  nonexistent  no  \n",
       "2       139         1    999         0  nonexistent  no  \n",
       "3       217         1    999         0  nonexistent  no  \n",
       "4       380         1    999         0  nonexistent  no  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicate columns\n",
    "df = df.loc[:, ~df.columns.duplicated()]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32cca6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37084 entries, 0 to 37083\n",
      "Data columns (total 25 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Customer_id     37084 non-null  int64  \n",
      " 1   age             37084 non-null  int64  \n",
      " 2   job             37084 non-null  object \n",
      " 3   marital         37084 non-null  object \n",
      " 4   education       37084 non-null  object \n",
      " 5   default         37084 non-null  object \n",
      " 6   housing         37084 non-null  object \n",
      " 7   loan            37084 non-null  object \n",
      " 8   Region_Code     37084 non-null  object \n",
      " 9   State_Code      37084 non-null  object \n",
      " 10  City_Code       37084 non-null  object \n",
      " 11  emp.var.rate    37084 non-null  float64\n",
      " 12  cons.price.idx  37084 non-null  float64\n",
      " 13  cons.conf.idx   37084 non-null  float64\n",
      " 14  euribor3m       37084 non-null  float64\n",
      " 15  nr.employed     37084 non-null  float64\n",
      " 16  contact         37084 non-null  object \n",
      " 17  month           37084 non-null  object \n",
      " 18  day_of_week     37084 non-null  object \n",
      " 19  duration        37084 non-null  int64  \n",
      " 20  campaign        37084 non-null  int64  \n",
      " 21  pdays           37084 non-null  int64  \n",
      " 22  previous        37084 non-null  int64  \n",
      " 23  poutcome        37084 non-null  object \n",
      " 24  y               37084 non-null  object \n",
      "dtypes: float64(5), int64(6), object(14)\n",
      "memory usage: 7.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b28ae1d",
   "metadata": {},
   "source": [
    "##### Dealing with the city, state and region columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5647fdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d788e3c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:2263\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:2273\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(st\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m      2\u001b[0m     match \u001b[38;5;241m=\u001b[39m rg\u001b[38;5;241m.\u001b[39mloc[(rg\u001b[38;5;241m.\u001b[39mRegion_Code \u001b[38;5;241m==\u001b[39m st[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRegion_Code\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[i])][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRegion_Name\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(match[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      4\u001b[0m     st[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRegion_Code\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(match)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:981\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    978\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m--> 981\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_value(key)\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m    985\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:1089\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1088\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1089\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_loc(label)\n\u001b[0;32m   1090\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_get_values_for_loc(\u001b[38;5;28mself\u001b[39m, loc, label)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "for i in range(st.shape[0]):\n",
    "    match = rg.loc[(rg.Region_Code == st['Region_Code'].iloc[i])]['Region_Name']\n",
    "    print(match[0])\n",
    "    st['Region_Code'].iloc[i] = list(match)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd8cdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9e9ef1e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'temp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(temp\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m      2\u001b[0m     match \u001b[38;5;241m=\u001b[39m st\u001b[38;5;241m.\u001b[39mloc[(st\u001b[38;5;241m.\u001b[39mState_Code \u001b[38;5;241m==\u001b[39m temp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mState_Code\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[i])][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mState_Name\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m     temp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mState_Code\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(match)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'temp' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(temp.shape[0]):\n",
    "    match = st.loc[(st.State_Code == temp['State_Code'].iloc[i])]['State_Name']\n",
    "    temp['State_Code'].iloc[i] = list(match)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f2cb227",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'temp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(temp\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      3\u001b[0m         match \u001b[38;5;241m=\u001b[39m rg\u001b[38;5;241m.\u001b[39mloc[(rg\u001b[38;5;241m.\u001b[39mRegion_Code \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mint\u001b[39m(temp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRegion_Code\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[i]))][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRegion_Name\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'temp' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(temp.shape[0]):\n",
    "    try:\n",
    "        match = rg.loc[(rg.Region_Code == int(temp['Region_Code'].iloc[i]))]['Region_Name']\n",
    "        temp['Region_Code'].iloc[i] = list(match)[0]\n",
    "    except:\n",
    "        None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53219aee",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'temp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m temp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRegion_Code\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'temp' is not defined"
     ]
    }
   ],
   "source": [
    "temp['Region_Code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1ba40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "city.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01f476b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(temp.shape[0]):\n",
    "    try:\n",
    "        match = city.loc[(city.City_Code == temp['City_Code'].iloc[i])]['City_Name']\n",
    "        temp['City_Code'].iloc[i] = list(match)[0]\n",
    "    except:\n",
    "        None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365b0bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# megrging to the original data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7a3614",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad9a9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for Null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f250d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39252f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017960d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot all the categorical plots\n",
    "def plot_cat(colu):\n",
    "    default_cnt = df[str(colu)].value_counts()\n",
    "    plt.figure(figsize = (12, 5))\n",
    "    default_cnt.plot(kind = \"bar\")\n",
    "    plt.title(str(colu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95674e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = list(df.columns[2:11]) + list(df.columns[16:19]) +list(df.columns[23:24])\n",
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5902476a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat:\n",
    "    plot_cat(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17160db3",
   "metadata": {},
   "source": [
    "#### observations from categorical columns\n",
    "\n",
    "1. Job columns - The jobs are well distributed with admin jobs being the most\n",
    "\n",
    "2. martial columns - There are more married individuals\n",
    "\n",
    "3. Education - Most of the people have received university level of education\n",
    "\n",
    "4. Most of them don't have a credit default\n",
    "\n",
    "5. Most of them have housing loans and there are also some rows where the data is not avaiable, we can drop these rows\n",
    "\n",
    "6. Most people belong to region 4 i.e West region\n",
    "\n",
    "7. Most people have state s2 i.e California\n",
    "\n",
    "8. Let's ignore the city code, it will just make the task tough\n",
    "\n",
    "9. Most of them are contacted via cellular\n",
    "\n",
    "10. Most people are last contacted in the month of may\n",
    "\n",
    "11. There's not much difference in the last day of the week they were contacted\n",
    "\n",
    "12. The data for the previous campaign is not available for most rows\n",
    "\n",
    "*Remove all the rows where data is not available*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e4ca64",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_count = df['y'].value_counts()\n",
    "plt.figure(figsize = (8, 5))\n",
    "target_count.plot(kind = \"bar\").set(title = \"Target Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358a736b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot with campign success\n",
    "def plot_col2(col):\n",
    "    # let's create a temporary data frame\n",
    "    try:\n",
    "        temp = pd.DataFrame()\n",
    "        temp['No'] = df[df['y'] == 'no'][str(col)].value_counts()\n",
    "        temp['Yes'] = df[df['y'] == 'yes'][str(col)].value_counts()\n",
    "        temp.plot(kind='bar')\n",
    "        plt.xlabel(f'{col}')\n",
    "        plt.ylabel('Number of clients')\n",
    "        plt.title('Distribution of {} and deposit'.format(col))\n",
    "    except:\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e64885b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping state and city bz of many categories it will be a problem to encode at a later stage, b/w we are covering the region\n",
    "fc =['job',\n",
    " 'marital',\n",
    " 'education',\n",
    " 'default',\n",
    " 'housing',\n",
    " 'loan',\n",
    " 'Region_Code',\n",
    " 'contact',\n",
    " 'month',\n",
    " 'day_of_week',\n",
    "   'poutcome' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab206cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.housing.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f4da29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with missing values\n",
    "\n",
    "df.drop(df[df.housing == 'unknown'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a139b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df.Region_Code == 'Na'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7517ad75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df.marital == 'unknown'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a284e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df.job == 'unknown'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1cd99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df.education == 'unknown'].index, inplace=True)\n",
    "df.drop(df[df.default == 'unknown'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7c3752",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699ea782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting with respect to response\n",
    "for col in fc:\n",
    "    plot_col2(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5965b502",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "print(\"percentage of customers turned to buy term deposit this term : \",len(df.loc[(df.poutcome != \"success\") & (df.y == \"yes\")])/df.shape[0] *100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8228bcdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee09c46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the customer_id\n",
    "df.drop(columns=['Customer_id','City_Code', 'State_Code'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e1627c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the distribution of answers for each category with respect to result\n",
    "df[df['y'] == 'yes'].hist(figsize = (20,20))\n",
    "plt.title('Client has subscribed a term deposite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7634b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['y'] == 'no'].hist(figsize = (20,20))\n",
    "plt.title('Client has subscribed a term deposite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d3535b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.y = df.y.map({'no':0, 'yes':1}).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9799f996",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d70df71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the correlation matrix to get an idea of how each column is correlated with the other columns\n",
    "corr\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc195cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the categorical columns\n",
    "# Replacing values with binary ()\n",
    "df.contact = df.contact.map({'cellular': 1, 'telephone': 0}).astype('uint8') \n",
    "df.loan = df.loan.map({'yes': 1, 'unknown': 0, 'no' : 0}).astype('uint8')\n",
    "df.housing = df.housing.map({'yes': 1, 'unknown': 0, 'no' : 0}).astype('uint8')\n",
    "df.default = df.default.map({'no': 1, 'unknown': 0, 'yes': 0}).astype('uint8')\n",
    "df.pdays = df.pdays.replace(999, 0) # replace with 0 if not contact \n",
    "df.Region_Code = df.Region_Code.map({'Central' : 0, 'East' : 1, 'South' : 2, 'West' : 3, 'North' : 4})\n",
    "df.previous = df.previous.apply(lambda x: 1 if x > 0 else 0).astype('uint8') # binary has contact or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df741e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary if were was an outcome of marketing campane\n",
    "df.poutcome = df.poutcome.map({'nonexistent':0, 'failure':0, 'success':1}).astype('uint8') \n",
    "\n",
    "# change the range of Var Rate\n",
    "df['emp.var.rate'] = df['emp.var.rate'].apply(lambda x: x*-0.0001 if x > 0 else x*1)\n",
    "df['emp.var.rate'] = df['emp.var.rate'] * -1\n",
    "df['emp.var.rate'] = df['emp.var.rate'].apply(lambda x: -np.log(x) if x < 1 else np.log(x)).astype('uint8')\n",
    "\n",
    "# Multiply consumer index \n",
    "df['cons.price.idx'] = (df['cons.price.idx'] * 10).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758ddcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the sign (we want all be positive values)\n",
    "df['cons.conf.idx'] = df['cons.conf.idx'] * -1\n",
    "\n",
    "# re-scale variables\n",
    "df['nr.employed'] = np.log2(df['nr.employed']).astype('uint8')\n",
    "df['cons.price.idx'] = np.log2(df['cons.price.idx']).astype('uint8')\n",
    "df['cons.conf.idx'] = np.log2(df['cons.conf.idx']).astype('uint8')\n",
    "df.age = np.log(df.age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05612615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# less space\n",
    "df.euribor3m = df.euribor3m.astype('uint8')\n",
    "df.campaign = df.campaign.astype('uint8')\n",
    "df.pdays = df.pdays.astype('uint8')\n",
    "\n",
    "# function to One Hot Encoding\n",
    "def encode(data, col):\n",
    "    return pd.concat([df, pd.get_dummies(col, prefix=col.name)], axis=1)\n",
    "\n",
    "# One Hot encoding of 3 variable \n",
    "df = encode(df, df.job)\n",
    "df = encode(df, df.month)\n",
    "df = encode(df, df.day_of_week)\n",
    "\n",
    "# Drop tranfromed features\n",
    "df.drop(['job', 'month', 'day_of_week'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b89f404",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5d6e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorizing duration \n",
    "def duration(df):\n",
    "    df.loc[df['duration'] <= 102, 'duration'] = 1\n",
    "    df.loc[(df['duration'] > 102) & (df['duration'] <= 180)  , 'duration'] = 2\n",
    "    df.loc[(df['duration'] > 180) & (df['duration'] <= 319)  , 'duration'] = 3\n",
    "    df.loc[(df['duration'] > 319) & (df['duration'] <= 645), 'duration'] = 4\n",
    "    df.loc[df['duration']  > 645, 'duration'] = 5\n",
    "    return df\n",
    "duration(df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe4ad5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "y = df.y\n",
    "# Create target encoder object and transform two value\n",
    "target_encode = ce.target_encoder.TargetEncoder(cols=['marital', 'education']).fit(df, y)\n",
    "numeric_dataset = target_encode.transform(df)\n",
    "# drop target variable\n",
    "numeric_dataset.drop('y', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042d28ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e467439a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Check numerical data set'''\n",
    "display(numeric_dataset.head(3), numeric_dataset.shape, y.shape)\n",
    "display('We observe 41175 rows and 44 numerical features after transformation. Target variable shape is (41175, 0 ) as expected')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a9ed74",
   "metadata": {},
   "source": [
    "##### Model Training with various predictive models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6211bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ba874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8703a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 11\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(numeric_dataset, y, test_size=0.2, random_state=random_state)\n",
    "# collect excess data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0d1331",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Build pipline of classifiers'''\n",
    "# set all CPU\n",
    "n_jobs = -1\n",
    "# LogisticRegression\n",
    "pipe_lr = Pipeline([('lr', LogisticRegression(random_state=random_state, n_jobs=n_jobs, max_iter=500))])\n",
    "# RandomForestClassifier\n",
    "pipe_rf = Pipeline([('rf', RandomForestClassifier(random_state=random_state, oob_score=True, n_jobs=n_jobs))])\n",
    "# KNeighborsClassifier\n",
    "pipe_knn = Pipeline([('knn', KNeighborsClassifier(n_jobs=n_jobs))])\n",
    "# DecisionTreeClassifier\n",
    "pipe_dt = Pipeline([('dt', DecisionTreeClassifier(random_state=random_state, max_features='auto'))])\n",
    "# BaggingClassifier\n",
    "# note we use SGDClassifier as classier inside BaggingClassifier\n",
    "pipe_bag = Pipeline([('bag',BaggingClassifier(base_estimator=SGDClassifier(random_state=random_state, n_jobs=n_jobs, max_iter=1500),\\\n",
    "                                              random_state=random_state,oob_score=True,n_jobs=n_jobs))])\n",
    "# SGDClassifier\n",
    "pipe_sgd = Pipeline([('sgd', SGDClassifier(random_state=random_state, n_jobs=n_jobs, max_iter=1500))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60151004",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Set parameters for Grid Search '''\n",
    "# set number \n",
    "cv = StratifiedKFold(shuffle=True, n_splits=5, random_state=random_state)\n",
    "# set for LogisticRegression\n",
    "grid_params_lr = [{\n",
    "                'lr__penalty': ['l2'],\n",
    "                'lr__C': [0.3, 0.6, 0.7],\n",
    "                'lr__solver': ['sag']\n",
    "                }]\n",
    "# set for RandomForestClassifier\n",
    "grid_params_rf = [{\n",
    "                'rf__criterion': ['entropy'],\n",
    "                'rf__min_samples_leaf': [80, 100],\n",
    "                'rf__max_depth': [25, 27],\n",
    "                'rf__min_samples_split': [3, 5],\n",
    "                'rf__n_estimators' : [60, 70]\n",
    "                }]\n",
    "# set for KNeighborsClassifier\n",
    "grid_params_knn = [{'knn__n_neighbors': [16,17,18]}]\n",
    "\n",
    "# set for DecisionTreeClassifier\n",
    "grid_params_dt = [{\n",
    "                'dt__max_depth': [8, 10],\n",
    "                'dt__min_samples_leaf': [1, 3, 5, 7]\n",
    "                  }]\n",
    "# set for BaggingClassifier\n",
    "grid_params_bag = [{'bag__n_estimators': [10, 15, 20]}]\n",
    "\n",
    "# set for SGDClassifier\n",
    "grid_params_sgd = [{\n",
    "                    'sgd__loss': ['log', 'huber'],\n",
    "                    'sgd__learning_rate': ['adaptive'],\n",
    "                    'sgd__eta0': [0.001, 0.01, 0.1],\n",
    "                    'sgd__penalty': ['l1', 'l2', 'elasticnet'], \n",
    "                    'sgd__alpha':[0.1, 1, 5, 10]\n",
    "                    }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6784c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Grid search objects'''\n",
    "# for LogisticRegression\n",
    "gs_lr = GridSearchCV(pipe_lr, param_grid=grid_params_lr,\n",
    "                     scoring='accuracy', cv=cv) \n",
    "# for RandomForestClassifier\n",
    "gs_rf = GridSearchCV(pipe_rf, param_grid=grid_params_rf,\n",
    "                     scoring='accuracy', cv=cv)\n",
    "# for KNeighborsClassifier\n",
    "gs_knn = GridSearchCV(pipe_knn, param_grid=grid_params_knn,\n",
    "                     scoring='accuracy', cv=cv)\n",
    "# for DecisionTreeClassifier\n",
    "gs_dt = GridSearchCV(pipe_dt, param_grid=grid_params_dt,\n",
    "                     scoring='accuracy', cv=cv)\n",
    "# for BaggingClassifier\n",
    "gs_bag = GridSearchCV(pipe_bag, param_grid=grid_params_bag,\n",
    "                     scoring='accuracy', cv=cv)\n",
    "# for SGDClassifier\n",
    "gs_sgd = GridSearchCV(pipe_sgd, param_grid=grid_params_sgd,\n",
    "                     scoring='accuracy', cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860babcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models that we iterate over\n",
    "look_for = [gs_lr, gs_rf, gs_knn, gs_dt, gs_bag, gs_sgd]\n",
    "# dict for later use \n",
    "model_dict = {0:'Logistic_reg', 1:'RandomForest', 2:'Knn', 3:'DesionTree', 4:'Bagging with SGDClassifier', 5:'SGD Class'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1810e668",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "''' Function to iterate over models and obtain results'''\n",
    "# set empty dicts and list\n",
    "result_acc = {}\n",
    "result_auc = {}\n",
    "models = []\n",
    "\n",
    "for index, model in enumerate(look_for):\n",
    "        start = time.time()\n",
    "        print()\n",
    "        print('+++++++ Start New Model ++++++++++++++++++++++')\n",
    "        print('Estimator is {}'.format(model_dict[index]))\n",
    "        model.fit(X_train, y_train)\n",
    "        print('---------------------------------------------')\n",
    "        print('best params {}'.format(model.best_params_))\n",
    "        print('best score is {}'.format(model.best_score_))\n",
    "        auc = roc_auc_score(y_test, model.predict_proba(X_test)[:,1])\n",
    "        print('---------------------------------------------')\n",
    "        print('ROC_AUC is {} and accuracy rate is {}'.format(auc, model.score(X_test, y_test)))\n",
    "        end = time.time()\n",
    "        print('It lasted for {} sec'.format(round(end - start, 3)))\n",
    "        print('++++++++ End Model +++++++++++++++++++++++++++')\n",
    "        print()\n",
    "        print()\n",
    "        models.append(model.best_estimator_)\n",
    "        result_acc[index] = model.best_score_\n",
    "        result_auc[index] = auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884efeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model_dict.values(), result_acc.values(), c='r')\n",
    "plt.plot(model_dict.values(), result_auc.values(), c='b')\n",
    "plt.xlabel('Models')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Accouracy and ROC_AUC')\n",
    "plt.title('Result of Grid Search')\n",
    "plt.legend(['Accuracy', 'ROC_AUC'])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f1b9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can observe that the RandomForest classifier outperformed all the other Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2605b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Model performance during Grid Search \"\"\"\n",
    "pd.DataFrame(list(zip(model_dict.values(), result_acc.values(), result_auc.values())), \\\n",
    "                  columns=['Model', 'Accuracy_rate','Roc_auc_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a261a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Build bar plot of feature importance of the best model '''\n",
    "\n",
    "def build_feature_importance(model, X_train, y_train):\n",
    "    \n",
    "    models = RandomForestClassifier(criterion='entropy', random_state=11, oob_score=True, n_jobs=-1, \\\n",
    "                           max_depth=25, min_samples_leaf=80, min_samples_split=3, n_estimators=70)\n",
    "    models.fit(X_train, y_train)\n",
    "    data = pd.DataFrame(models.feature_importances_, X_train.columns, columns=[\"feature\"])\n",
    "    data = data.sort_values(by='feature', ascending=False).reset_index()\n",
    "    plt.figure(figsize=[6,6])\n",
    "    sns.barplot(x='index', y='feature', data=data[:10], palette=\"Blues_d\")\n",
    "    plt.title('Feature inportance of Random Forest after Grid Search')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show();\n",
    "    \n",
    "build_feature_importance(RandomForestClassifier, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd570e1",
   "metadata": {},
   "source": [
    "###### We can infer the feature importance as shown above"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
